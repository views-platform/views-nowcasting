{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIEWS-Nowcasting\n",
    "\n",
    "This notebook walks your through the VIEWS-nowcasting model. This model aims to provide more timely estimates for UCDP data than the candidate data provides. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pdx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import tabula\n",
    "import xlwings as xw\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from nowcast import * #plot_statebased, plot_nonstate, plot_onesided \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# VIEWS 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "#from views_forecasts.extensions import *\n",
    "\n",
    "# Ingester\n",
    "from ingester3.config import source_db_path\n",
    "from ingester3.Country import Country\n",
    "from ingester3.extensions import *\n",
    "from ingester3.ViewsMonth import ViewsMonth\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "home = os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering all data\n",
    "\n",
    "Setting the training years to range from 2018 until 2022 **AND** the test year for 2023. This allows for all of the candidate data to be used. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nowcasting_master_final_data_1.csv', index_col=(['month_id','c_id']))\n",
    "\n",
    "# drop source_version\n",
    "df.drop('source_version', axis=1, inplace=True)\n",
    "\n",
    "# Training set uses data from 2018 until 2022\n",
    "train = df.loc[(df['year'] >= 2018) & (df['year'] < 2023)]\n",
    "\n",
    "# Test set uses 2022\n",
    "test = df.loc[(df['year'] > 2022)]\n",
    "\n",
    "# Training and test Labels\n",
    "y_train = train['sb_final_best_ln']\n",
    "y_test = test['sb_final_best_ln']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = [\n",
    "    'candidate_sb_best_sum_nokgi_ln1','candidate_os_best_sum_nokgi_ln1','candidate_ns_best_sum_nokgi_ln1', \n",
    "    'candidate_sb_best_count_nokgi','candidate_ns_best_count_nokgi','candidate_os_best_count_nokgi',\n",
    "    'acled_sb_fat_ln', 'acled_sb_fat_ln_1', 'acled_sb_fat_ln_2',\n",
    "    'acled_sb_count','acled_ns_count', 'acled_os_count',\n",
    "    'acled_pr_count',\n",
    "    'topic_conflict_1', 'topic_judiciary_1', 'topic_diplomacy_1',\n",
    "    'vdem_v2x_delibdem', 'vdem_v2x_clphy', 'vdem_v2x_rule', 'vdem_v2x_freexp', \n",
    "    'acled_sb_fat_ln_24', 'acled_sb_fat_ln_3', 'sb_final_best_ln_24','sb_final_best_ln_12', \n",
    "    'month', 'candidate_sb_best_sum_nokgi_ln1_lag1', 'candidate_sb_best_sum_nokgi_ln1_lag2','candidate_sb_best_sum_nokgi_ln1_lag3'\n",
    "    ] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_new = train[short_list]\n",
    "test_new = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to get list of all columns\n",
    "\n",
    "#list(train_new.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Candidate vs GED final vs ALCED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_statebased(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nonstate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_onesided(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of training set:', len(train), '\\n' 'Length of test set:', len(test))\n",
    "\n",
    "year_min = min(train[\"year\"].min(), test[\"year\"].min())\n",
    "year_max = max(train[\"year\"].max(), test[\"year\"].max())\n",
    "\n",
    "# Create bin edges from the minimum year to the maximum year\n",
    "bin_edges = np.arange(year_min - 0.5, year_max + 1.5, 1)\n",
    "\n",
    "# Plot histograms \n",
    "train[\"year\"].hist(bins=bin_edges, figsize=(10, 5), label=\"training set\", alpha=0.7, rwidth=0.5)\n",
    "test[\"year\"].hist(bins=bin_edges, figsize=(10, 5), label=\"test set\", alpha=0.7, rwidth=0.5)\n",
    "\n",
    "\n",
    "plt.title(\"Observations by Year in Train and Test Sets\")\n",
    "plt.ylim(0, 2500)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Observations\")\n",
    "plt.grid(False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Model 1: Simple model taking only the basic conflict variables\n",
    "\n",
    "Model 2: Simple model taking only the basic conflict variables + ACLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = [\n",
    "    'candidate_sb_best_sum_nokgi_ln1','candidate_os_best_sum_nokgi_ln1','candidate_ns_best_sum_nokgi_ln1', \n",
    "    'candidate_sb_best_count_nokgi','candidate_ns_best_count_nokgi','candidate_os_best_count_nokgi', \n",
    "    'month', 'candidate_sb_best_sum_nokgi_ln1_lag1', 'candidate_sb_best_sum_nokgi_ln1_lag2','candidate_sb_best_sum_nokgi_ln1_lag3',\n",
    "    ] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_minimal = train[short_list]\n",
    "test_minimal = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Test and train sets\n",
    "\n",
    "# Y test\n",
    "y_train = train['sb_final_best_ln']\n",
    "y_test = test['sb_final_best_ln']\n",
    "\n",
    "X_train_1 = train_minimal\n",
    "X_test_1 = test_minimal\n",
    "\n",
    "# Random Forest Model (non-log)\n",
    "rf_model2 = RandomForestRegressor(random_state=17)\n",
    "rf_model2.fit(X_train_1, y_train)\n",
    "\n",
    "rf_m2_predictions = rf_model2.predict(X_test_1)\n",
    "\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, rf_m2_predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(\"Random Forest Regressor MSE:\", mse)\n",
    "print(\"Random Forest Regressor RMSE:\", rmse)\n",
    "print('')\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "## PLOTTING\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "# Creating jitter by adding a small random number to x and y coordinates\n",
    "x_jittered = rf_m2_predictions + np.random.normal(0, jitter_amount, size=len(rf_m2_predictions))\n",
    "y_jittered = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "# Creating subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "# Original plot\n",
    "ax[0].scatter(rf_m2_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0].set_title('Actuals vs Predictions')\n",
    "ax[0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0].set_xlim([-1, 11])\n",
    "ax[0].set_ylim([-1, 11])\n",
    "ax[0].grid(True)\n",
    "# Plot with jitter\n",
    "ax[1].scatter(x_jittered, y_jittered, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1].set_title('Plot with Jitter')\n",
    "ax[1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1].set_xlim([-1, 11])\n",
    "ax[1].set_ylim([-1, 11])\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: With ACLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = [\n",
    "    'candidate_sb_best_sum_nokgi_ln1','candidate_os_best_sum_nokgi_ln1','candidate_ns_best_sum_nokgi_ln1', \n",
    "    'candidate_sb_best_count_nokgi','candidate_ns_best_count_nokgi','candidate_os_best_count_nokgi', \n",
    "    'month', 'candidate_sb_best_sum_nokgi_ln1_lag1', 'candidate_sb_best_sum_nokgi_ln1_lag2','candidate_sb_best_sum_nokgi_ln1_lag3',\n",
    "    'acled_sb_fat_ln', 'acled_sb_fat_ln_1', 'acled_sb_fat_ln_2','acled_pr_count',\n",
    "    'acled_sb_count','acled_ns_count', 'acled_os_count','acled_sb_fat_ln_24', 'acled_sb_fat_ln_3'\n",
    "    ] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_acled = train[short_list]\n",
    "test_acled = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Test and train sets\n",
    "\n",
    "# Y test\n",
    "y_train = train['sb_final_best_ln']\n",
    "y_test = test['sb_final_best_ln']\n",
    "\n",
    "X_train_1 = train_acled\n",
    "X_test_1 = test_acled\n",
    "\n",
    "# Random Forest Model (non-log)\n",
    "rf_model2 = RandomForestRegressor(random_state=17)\n",
    "rf_model2.fit(X_train_1, y_train)\n",
    "\n",
    "rf_m2_predictions = rf_model2.predict(X_test_1)\n",
    "\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, rf_m2_predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(\"Random Forest Regressor MSE:\", mse)\n",
    "print(\"Random Forest Regressor RMSE:\", rmse)\n",
    "print('')\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "## PLOTTING\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "# Creating jitter by adding a small random number to x and y coordinates\n",
    "x_jittered = rf_m2_predictions + np.random.normal(0, jitter_amount, size=len(rf_m2_predictions))\n",
    "y_jittered = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "# Creating subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "# Original plot\n",
    "ax[0].scatter(rf_m2_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0].set_title('Actuals vs Predictions')\n",
    "ax[0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0].set_xlim([-1, 11])\n",
    "ax[0].set_ylim([-1, 11])\n",
    "ax[0].grid(True)\n",
    "# Plot with jitter\n",
    "ax[1].scatter(x_jittered, y_jittered, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1].set_title('Plot with Jitter')\n",
    "ax[1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1].set_xlim([-1, 11])\n",
    "ax[1].set_ylim([-1, 11])\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: ACLED Model with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = [\n",
    "    'candidate_sb_best_sum_nokgi_ln1','candidate_os_best_sum_nokgi_ln1','candidate_ns_best_sum_nokgi_ln1', \n",
    "    'candidate_sb_best_count_nokgi','candidate_ns_best_count_nokgi','candidate_os_best_count_nokgi', \n",
    "    'month', 'candidate_sb_best_sum_nokgi_ln1_lag1', 'candidate_sb_best_sum_nokgi_ln1_lag2','candidate_sb_best_sum_nokgi_ln1_lag3',\n",
    "    'acled_sb_fat_ln', 'acled_sb_fat_ln_1', 'acled_sb_fat_ln_2','acled_pr_count',\n",
    "    'acled_sb_count','acled_ns_count', 'acled_os_count','acled_sb_fat_ln_24', 'acled_sb_fat_ln_3',\n",
    "    'topic_conflict_1', 'topic_judiciary_1', 'topic_diplomacy_1',\n",
    "    ] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_long = train[short_list]\n",
    "test_long = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Test and train sets\n",
    "\n",
    "# Y test\n",
    "y_train = train['sb_final_best_ln']\n",
    "y_test = test['sb_final_best_ln']\n",
    "\n",
    "X_train_1 = train_long\n",
    "X_test_1 = test_long\n",
    "\n",
    "# Random Forest Model (non-log)\n",
    "rf_model2 = RandomForestRegressor(random_state=17)\n",
    "rf_model2.fit(X_train_1, y_train)\n",
    "\n",
    "rf_m2_predictions = rf_model2.predict(X_test_1)\n",
    "\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, rf_m2_predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(\"Random Forest Regressor MSE:\", mse)\n",
    "print(\"Random Forest Regressor RMSE:\", rmse)\n",
    "print('')\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "## PLOTTING\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "# Creating jitter by adding a small random number to x and y coordinates\n",
    "x_jittered = rf_m2_predictions + np.random.normal(0, jitter_amount, size=len(rf_m2_predictions))\n",
    "y_jittered = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "# Creating subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "# Original plot\n",
    "ax[0].scatter(rf_m2_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0].set_title('Actuals vs Predictions')\n",
    "ax[0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0].set_xlim([-1, 11])\n",
    "ax[0].set_ylim([-1, 11])\n",
    "ax[0].grid(True)\n",
    "# Plot with jitter\n",
    "ax[1].scatter(x_jittered, y_jittered, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1].set_title('Plot with Jitter')\n",
    "ax[1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1].set_xlim([-1, 11])\n",
    "ax[1].set_ylim([-1, 11])\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Training long with VDEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = [\n",
    "    'candidate_sb_best_sum_nokgi_ln1','candidate_os_best_sum_nokgi_ln1','candidate_ns_best_sum_nokgi_ln1', \n",
    "    'candidate_sb_best_count_nokgi','candidate_ns_best_count_nokgi','candidate_os_best_count_nokgi', \n",
    "    'month', 'candidate_sb_best_sum_nokgi_ln1_lag1', 'candidate_sb_best_sum_nokgi_ln1_lag2','candidate_sb_best_sum_nokgi_ln1_lag3',\n",
    "    'acled_sb_fat_ln', 'acled_sb_fat_ln_1', 'acled_sb_fat_ln_2','acled_pr_count',\n",
    "    'acled_sb_count','acled_ns_count', 'acled_os_count','acled_sb_fat_ln_24', 'acled_sb_fat_ln_3',\n",
    "    'topic_conflict_1', 'topic_judiciary_1', 'topic_diplomacy_1',\n",
    "    'vdem_v2x_delibdem', 'vdem_v2x_clphy', 'vdem_v2x_rule', 'vdem_v2x_freexp'\n",
    "    ] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_longer = train[short_list]\n",
    "test_longer = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Test and train sets\n",
    "\n",
    "# Y test\n",
    "y_train = train['sb_final_best_ln']\n",
    "y_test = test['sb_final_best_ln']\n",
    "\n",
    "X_train_1 = train_longer\n",
    "X_test_1 = test_longer\n",
    "\n",
    "# Random Forest Model (non-log)\n",
    "rf_model2 = RandomForestRegressor(random_state=17)\n",
    "rf_model2.fit(X_train_1, y_train)\n",
    "\n",
    "rf_m2_predictions = rf_model2.predict(X_test_1)\n",
    "\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, rf_m2_predictions)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "\n",
    "print(\"Random Forest Regressor MSE:\", mse)\n",
    "print(\"Random Forest Regressor RMSE:\", rmse)\n",
    "print('')\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "## PLOTTING\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "# Creating jitter by adding a small random number to x and y coordinates\n",
    "x_jittered = rf_m2_predictions + np.random.normal(0, jitter_amount, size=len(rf_m2_predictions))\n",
    "y_jittered = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "# Creating subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
    "# Original plot\n",
    "ax[0].scatter(rf_m2_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0].set_title('Actuals vs Predictions')\n",
    "ax[0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0].set_xlim([-1, 11])\n",
    "ax[0].set_ylim([-1, 11])\n",
    "ax[0].grid(True)\n",
    "# Plot with jitter\n",
    "ax[1].scatter(x_jittered, y_jittered, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1].set_title('Plot with Jitter')\n",
    "ax[1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1].set_xlim([-1, 11])\n",
    "ax[1].set_ylim([-1, 11])\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an XgBoost Model instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = [\n",
    "    'candidate_sb_best_sum_nokgi_ln1','candidate_os_best_sum_nokgi_ln1','candidate_ns_best_sum_nokgi_ln1', \n",
    "    'candidate_sb_best_count_nokgi','candidate_ns_best_count_nokgi','candidate_os_best_count_nokgi', \n",
    "    'month', 'candidate_sb_best_sum_nokgi_ln1_lag1', 'candidate_sb_best_sum_nokgi_ln1_lag2','candidate_sb_best_sum_nokgi_ln1_lag3',\n",
    "    'acled_sb_fat_ln', 'acled_sb_fat_ln_1', 'acled_sb_fat_ln_2','acled_pr_count',\n",
    "    'acled_sb_count','acled_ns_count', 'acled_os_count','acled_sb_fat_ln_24', 'acled_sb_fat_ln_3',\n",
    "    'topic_conflict_1', 'topic_judiciary_1', 'topic_diplomacy_1',\n",
    "    'vdem_v2x_delibdem', 'vdem_v2x_clphy', 'vdem_v2x_rule', 'vdem_v2x_freexp'\n",
    "    ] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_longer = train[short_list]\n",
    "test_longer = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBRegressor model\n",
    "\n",
    "xgb_m3_regressor = xgb.XGBRegressor(eval_metric='rmsle',\n",
    "                                       learning_rate = 0.02,\n",
    "                                       max_depth = 6,\n",
    "                                       n_estimators = 250,\n",
    "                                       colsample_bytree = 0.6,\n",
    "                                       subsample = 0.8,\n",
    "                                       #reg_alpha = 0.4,\n",
    "                                       #reg_lambda =0.4,\n",
    "                                       random_state = 17\n",
    "                                      ) \n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "xgb_m3_regressor.fit(train_longer, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_m3_predictions = xgb_m3_regressor.predict(test_longer)\n",
    "\n",
    "xgb_m3_predictions = np.maximum(xgb_m3_predictions, 0)\n",
    "\n",
    "# Evaluate the model using MSE or any other suitable regression metric\n",
    "mse_m3_xgb = mean_squared_error(y_test, xgb_m3_predictions)\n",
    "print(\"XGBoost MSE:\", mse_m3_xgb)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(mse_m3_xgb))\n",
    "print(' ')\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "## PLOTTING (2x2 layout)\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Jittered predictions for XGBoost\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Jittered predictions for Candidate Model\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi_ln1']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# 1. XGBoost Predictions vs Actual (Original)\n",
    "ax[0, 0].scatter(xgb_m3_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 0].set_title('XGBoost: Predicted vs Actual')\n",
    "ax[0, 0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 0].set_xlim([-1, 11])\n",
    "ax[0, 0].set_ylim([-1, 11])\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# 2. XGBoost Predictions vs Actual (with Jitter)\n",
    "ax[0, 1].scatter(x_jittered_xgb, y_jittered_xgb, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 1].set_title('XGBoost: Plot with Jitter')\n",
    "ax[0, 1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 1].set_xlim([-1, 11])\n",
    "ax[0, 1].set_ylim([-1, 11])\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# 3. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 0].scatter(test['candidate_sb_best_sum_nokgi_ln1'], y_test, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 0].set_title('Candidate vs GED Final')\n",
    "ax[1, 0].set_xlabel('Candidate Values (Logged)')\n",
    "ax[1, 0].set_ylabel('GED Final Values (Logged)')\n",
    "ax[1, 0].set_xlim([-1, 11])\n",
    "ax[1, 0].set_ylim([-1, 11])\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# 4. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 1].scatter(x_jittered_candidate, y_jittered_candidate, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 1].set_title('Candidate: Plot with Jitter')\n",
    "ax[1, 1].set_xlabel('Candidate Predicted Values (Logged)')\n",
    "ax[1, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1, 1].set_xlim([-1, 11])\n",
    "ax[1, 1].set_ylim([-1, 11])\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# EVAL METRICS\n",
    "# Assuming your RandomForest model is named 'rf_best' and is already trained\n",
    "feature_importances_xgb = xgb_m3_regressor.feature_importances_\n",
    "\n",
    "# Assuming 'X_train' is your training dataset\n",
    "feature_names_xgb = X_train_1.columns\n",
    "\n",
    "# Create a pandas DataFrame for easier visualization\n",
    "feature_importance_xgb = pd.DataFrame({'Feature': feature_names_xgb, 'Importance': feature_importances_xgb})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "feature_importance_xgb = feature_importance_xgb.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance scores\n",
    "feature_importance_xgb.head(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the XgBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a parameter grid to search\n",
    "param_grid = {\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.02],\n",
    "    'subsample': [0.4, 0.6, 0.8],\n",
    "    'colsample_bytree': [0.5,0.6, 0.7],\n",
    "    'n_estimators': [250, 500, 750],\n",
    "}\n",
    "\n",
    "# Time series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb_regressor = xgb.XGBRegressor(eval_metric='rmse')\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, cv=tscv, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_longer, y_train)\n",
    "\n",
    "# Best parameter set\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Best estimator with parameters set\n",
    "xgb_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best estimator\n",
    "xgb_m2_predictions = xgb_regressor.predict(test_longer)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, xgb_m2_predictions))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBRegressor model\n",
    "\n",
    "xgb_m3_regressor = xgb.XGBRegressor(eval_metric='rmse',\n",
    "                                       learning_rate = 0.01,\n",
    "                                       max_depth = 6,\n",
    "                                       n_estimators = 750,\n",
    "                                       colsample_bytree = 0.6,\n",
    "                                       subsample = 0.8,\n",
    "                                       #reg_alpha = 0.4,\n",
    "                                       #reg_lambda =0.4,\n",
    "                                       min_child_weight=1,\n",
    "                                       gamma=0.1,\n",
    "                                       booster='dart',\n",
    "                                       random_state = 17\n",
    "                                      ) \n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "xgb_m3_regressor.fit(train_longer, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_m3_predictions = xgb_m3_regressor.predict(test_longer)\n",
    "\n",
    "xgb_m3_predictions = np.maximum(xgb_m3_predictions, 0)\n",
    "\n",
    "# Evaluate the model using MSE or any other suitable regression metric\n",
    "mse_m3_xgb = mean_squared_error(y_test, xgb_m3_predictions)\n",
    "print(\"XGBoost MSE:\", mse_m3_xgb)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(mse_m3_xgb))\n",
    "print(' ')\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "## PLOTTING (2x2 layout)\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Jittered predictions for XGBoost\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Jittered predictions for Candidate Model\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi_ln1']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# 1. XGBoost Predictions vs Actual (Original)\n",
    "ax[0, 0].scatter(xgb_m3_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 0].set_title('XGBoost: Predicted vs Actual')\n",
    "ax[0, 0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 0].set_xlim([-1, 11])\n",
    "ax[0, 0].set_ylim([-1, 11])\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# 2. XGBoost Predictions vs Actual (with Jitter)\n",
    "ax[0, 1].scatter(x_jittered_xgb, y_jittered_xgb, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 1].set_title('XGBoost: Plot with Jitter')\n",
    "ax[0, 1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 1].set_xlim([-1, 11])\n",
    "ax[0, 1].set_ylim([-1, 11])\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# 3. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 0].scatter(test['candidate_sb_best_sum_nokgi_ln1'], y_test, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 0].set_title('Candidate vs GED Final')\n",
    "ax[1, 0].set_xlabel('Candidate Values (Logged)')\n",
    "ax[1, 0].set_ylabel('GED Final Values (Logged)')\n",
    "ax[1, 0].set_xlim([-1, 11])\n",
    "ax[1, 0].set_ylim([-1, 11])\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# 4. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 1].scatter(x_jittered_candidate, y_jittered_candidate, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 1].set_title('Candidate: Plot with Jitter')\n",
    "ax[1, 1].set_xlabel('Candidate Predicted Values (Logged)')\n",
    "ax[1, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1, 1].set_xlim([-1, 11])\n",
    "ax[1, 1].set_ylim([-1, 11])\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL METRICS\n",
    "# Assuming your RandomForest model is named 'rf_best' and is already trained\n",
    "feature_importances_xgb = xgb_m3_regressor.feature_importances_\n",
    "\n",
    "# Assuming 'X_train' is your training dataset\n",
    "feature_names_xgb = train_longer.columns\n",
    "\n",
    "# Create a pandas DataFrame for easier visualization\n",
    "feature_importance_xgb = pd.DataFrame({'Feature': feature_names_xgb, 'Importance': feature_importances_xgb})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "feature_importance_xgb = feature_importance_xgb.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance scores\n",
    "feature_importance_xgb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING (2x2 layout)\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Jittered predictions for XGBoost\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Jittered predictions for Candidate Model\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi_ln1']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# 1. XGBoost Predictions vs Actual (Original)\n",
    "ax[0, 0].scatter(xgb_m3_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 0].set_title('XGBoost: Predicted vs Actual')\n",
    "ax[0, 0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 0].set_xlim([-1, 11])\n",
    "ax[0, 0].set_ylim([-1, 11])\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# 2. XGBoost Predictions vs Actual (with Jitter)\n",
    "ax[0, 1].scatter(x_jittered_xgb, y_jittered_xgb, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 1].set_title('XGBoost: Plot with Jitter')\n",
    "ax[0, 1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 1].set_xlim([-1, 11])\n",
    "ax[0, 1].set_ylim([-1, 11])\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# 3. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 0].scatter(test['candidate_sb_best_sum_nokgi_ln1'], y_test, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 0].set_title('Candidate vs GED Final')\n",
    "ax[1, 0].set_xlabel('Candidate Values (Logged)')\n",
    "ax[1, 0].set_ylabel('GED Final Values (Logged)')\n",
    "ax[1, 0].set_xlim([-1, 11])\n",
    "ax[1, 0].set_ylim([-1, 11])\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# 4. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 1].scatter(x_jittered_candidate, y_jittered_candidate, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 1].set_title('Candidate: Plot with Jitter')\n",
    "ax[1, 1].set_xlabel('Candidate Predicted Values (Logged)')\n",
    "ax[1, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1, 1].set_xlim([-1, 11])\n",
    "ax[1, 1].set_ylim([-1, 11])\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Jitter parameters\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Create jittered versions of predictions\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi_ln1']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Extract hover info (assuming these are in the index)\n",
    "month_ids = test.index.get_level_values('month_id') if 'month_id' in test.index.names else test['month_id']\n",
    "c_ids = test.index.get_level_values('c_id') if 'c_id' in test.index.names else test['c_id']\n",
    "hover_text = [f\"month_id: {m}, c_id: {c}\" for m, c in zip(month_ids, c_ids)]\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=[\n",
    "    \"XGBoost: Predicted vs Actual\",\n",
    "    \"XGBoost: Plot with Jitter\",\n",
    "    \"Candidate vs GED Final\",\n",
    "    \"Candidate: Plot with Jitter\"\n",
    "])\n",
    "\n",
    "# 1. XGBoost: Predicted vs Actual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=xgb_m3_predictions,\n",
    "    y=y_test,\n",
    "    mode='markers',\n",
    "    marker=dict(color='crimson', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='XGB'\n",
    "), row=1, col=1)\n",
    "\n",
    "# 2. XGBoost: Jittered\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_jittered_xgb,\n",
    "    y=y_jittered_xgb,\n",
    "    mode='markers',\n",
    "    marker=dict(color='crimson', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='XGB Jitter'\n",
    "), row=1, col=2)\n",
    "\n",
    "# 3. Candidate vs Actual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=candidate_preds,\n",
    "    y=y_test,\n",
    "    mode='markers',\n",
    "    marker=dict(color='teal', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='Candidate'\n",
    "), row=2, col=1)\n",
    "\n",
    "# 4. Candidate: Jittered\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_jittered_candidate,\n",
    "    y=y_jittered_candidate,\n",
    "    mode='markers',\n",
    "    marker=dict(color='teal', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='Candidate Jitter'\n",
    "), row=2, col=2)\n",
    "\n",
    "# Add 45-degree line to each subplot\n",
    "for row in [1, 2]:\n",
    "    for col in [1, 2]:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[-1, 11],\n",
    "            y=[-1, 11],\n",
    "            mode='lines',\n",
    "            line=dict(color='black', dash='dash'),\n",
    "            showlegend=False\n",
    "        ), row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    width=1000,\n",
    "    title_text=\"Interactive Model Comparison Plots\",\n",
    ")\n",
    "\n",
    "# Set x and y limits for all plots\n",
    "for i in range(1, 5):\n",
    "    fig.update_xaxes(range=[-1, 11], row=(i - 1) // 2 + 1, col=(i - 1) % 2 + 1)\n",
    "    fig.update_yaxes(range=[-1, 11], row=(i - 1) // 2 + 1, col=(i - 1) % 2 + 1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Compute residuals and group\n",
    "test['residual'] = y_test - xgb_m3_predictions\n",
    "resid_by_country = test.groupby('c_id')['residual'].mean()\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "resid_df = resid_by_country.reset_index()\n",
    "resid_df.columns = ['c_id', 'avg_residual']\n",
    "resid_df = resid_df.sort_values(by='avg_residual', ascending=True)  #  sort here\n",
    "\n",
    "# Plot interactive bar chart\n",
    "fig = px.bar(\n",
    "    resid_df,\n",
    "    x='c_id',\n",
    "    y='avg_residual',\n",
    "    title='Average Residual by Country (c_id)',\n",
    "    labels={'c_id': 'Country (c_id)', 'avg_residual': 'Average Residual'},\n",
    "    hover_data={'c_id': True, 'avg_residual': True}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    height=500,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['residual'] = y_test - xgb_m3_predictions\n",
    "resid_by_country = test.groupby('c_id')['residual'].mean().sort_values()\n",
    "resid_by_country.plot(kind='bar', figsize=(12, 5), title='Average Residual by Country (c_id)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting to reduce residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBRegressor model\n",
    "\n",
    "xgb_m3_regressor = xgb.XGBRegressor(eval_metric='rmse',\n",
    "                                       learning_rate = 0.02,\n",
    "                                       max_depth = 12,\n",
    "                                       n_estimators = 500,\n",
    "                                       colsample_bytree = 0.8,\n",
    "                                       subsample = 0.8,\n",
    "                                       #reg_alpha = 0.4,\n",
    "                                       #reg_lambda =0.4,\n",
    "                                       min_child_weight=1,\n",
    "                                       gamma=0.1,\n",
    "                                       booster='dart',\n",
    "                                       random_state = 17\n",
    "                                      ) \n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "xgb_m3_regressor.fit(train_longer, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_m3_predictions = xgb_m3_regressor.predict(test_longer)\n",
    "\n",
    "xgb_m3_predictions = np.maximum(xgb_m3_predictions, 0)\n",
    "\n",
    "# Evaluate the model using MSE or any other suitable regression metric\n",
    "mse_m3_xgb = mean_squared_error(y_test, xgb_m3_predictions)\n",
    "print(\"XGBoost MSE:\", mse_m3_xgb)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(mse_m3_xgb))\n",
    "print(' ')\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "## PLOTTING (2x2 layout)\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Jittered predictions for XGBoost\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Jittered predictions for Candidate Model\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi_ln1']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# 1. XGBoost Predictions vs Actual (Original)\n",
    "ax[0, 0].scatter(xgb_m3_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 0].set_title('XGBoost: Predicted vs Actual')\n",
    "ax[0, 0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 0].set_xlim([-1, 11])\n",
    "ax[0, 0].set_ylim([-1, 11])\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# 2. XGBoost Predictions vs Actual (with Jitter)\n",
    "ax[0, 1].scatter(x_jittered_xgb, y_jittered_xgb, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 1].set_title('XGBoost: Plot with Jitter')\n",
    "ax[0, 1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 1].set_xlim([-1, 11])\n",
    "ax[0, 1].set_ylim([-1, 11])\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# 3. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 0].scatter(test['candidate_sb_best_sum_nokgi_ln1'], y_test, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 0].set_title('Candidate vs GED Final')\n",
    "ax[1, 0].set_xlabel('Candidate Values (Logged)')\n",
    "ax[1, 0].set_ylabel('GED Final Values (Logged)')\n",
    "ax[1, 0].set_xlim([-1, 11])\n",
    "ax[1, 0].set_ylim([-1, 11])\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# 4. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 1].scatter(x_jittered_candidate, y_jittered_candidate, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 1].set_title('Candidate: Plot with Jitter')\n",
    "ax[1, 1].set_xlabel('Candidate Predicted Values (Logged)')\n",
    "ax[1, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1, 1].set_xlim([-1, 11])\n",
    "ax[1, 1].set_ylim([-1, 11])\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# EVAL METRICS\n",
    "# Assuming your RandomForest model is named 'rf_best' and is already trained\n",
    "feature_importances_xgb = xgb_m3_regressor.feature_importances_\n",
    "\n",
    "# Assuming 'X_train' is your training dataset\n",
    "feature_names_xgb = X_train_1.columns\n",
    "\n",
    "# Create a pandas DataFrame for easier visualization\n",
    "feature_importance_xgb = pd.DataFrame({'Feature': feature_names_xgb, 'Importance': feature_importances_xgb})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "feature_importance_xgb = feature_importance_xgb.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance scores\n",
    "feature_importance_xgb.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['residual'] = y_test - xgb_m3_predictions\n",
    "resid_by_country = test.groupby('c_id')['residual'].mean().sort_values()\n",
    "resid_by_country.plot(kind='bar', figsize=(12, 5), title='Average Residual by Country (c_id)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving underpredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = [\n",
    "    'candidate_sb_best_sum_nokgi_ln1','candidate_os_best_sum_nokgi_ln1','candidate_ns_best_sum_nokgi_ln1', \n",
    "    'candidate_sb_best_count_nokgi','candidate_ns_best_count_nokgi','candidate_os_best_count_nokgi', \n",
    "    'month', 'candidate_sb_best_sum_nokgi_ln1_lag1', 'candidate_sb_best_sum_nokgi_ln1_lag2','candidate_sb_best_sum_nokgi_ln1_lag3',\n",
    "    'acled_sb_fat_ln', 'acled_sb_fat_ln_1', 'acled_sb_fat_ln_2','acled_pr_count',\n",
    "    'acled_sb_count','acled_ns_count', 'acled_os_count','acled_sb_fat_ln_24', 'acled_sb_fat_ln_3',\n",
    "    'topic_conflict_1', 'topic_judiciary_1', 'topic_diplomacy_1',\n",
    "    'vdem_v2x_delibdem', 'vdem_v2x_clphy', 'vdem_v2x_rule', 'vdem_v2x_freexp'\n",
    "    ] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_longer = train[short_list]\n",
    "test_longer = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# === First Pass: Base Model ===\n",
    "xgb_base = xgb.XGBRegressor(\n",
    "    eval_metric='rmse',\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    n_estimators=750,\n",
    "    colsample_bytree=0.6,\n",
    "    subsample=0.8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    booster='dart',\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "# Fit base model to get residuals\n",
    "xgb_base.fit(train_longer, y_train)\n",
    "train_preds = xgb_base.predict(train_longer)\n",
    "\n",
    "# Compute residuals\n",
    "train_residuals = y_train - train_preds\n",
    "\n",
    "# Reset index of train_longer and y_train\n",
    "train_longer = train_longer.copy()\n",
    "train_longer = train_longer.reset_index()\n",
    "y_train_reset = y_train.reset_index(drop=True)  # Align index with reset train_longer\n",
    "train_residuals = y_train_reset - train_preds   # Now residuals are aligned\n",
    "\n",
    "# Assign residuals\n",
    "train_longer['residual'] = train_residuals\n",
    "\n",
    "# Identify underpredicted countries (e.g., residual < -0.4)\n",
    "resid_by_cid = train_longer.groupby('c_id')['residual'].mean()\n",
    "underpredicted_cids = resid_by_cid[resid_by_cid < -0.38].index.tolist()\n",
    "\n",
    "# Assign sample weights\n",
    "train_longer['sample_weight'] = 1.0\n",
    "train_longer.loc[train_longer['c_id'].isin(underpredicted_cids), 'sample_weight'] = 2.0\n",
    "\n",
    "# === Second Pass: Weighted Model ===\n",
    "xgb_m3_regressor = xgb.XGBRegressor(\n",
    "    eval_metric='rmse',\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    n_estimators=750,\n",
    "    colsample_bytree=0.6,\n",
    "    subsample=0.8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    booster='dart',\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "# Refit using sample weights\n",
    "xgb_m3_regressor.fit(\n",
    "    train_longer[short_features],\n",
    "    y_train,\n",
    "    sample_weight=train_longer['sample_weight']\n",
    ")\n",
    "\n",
    "# Predict on test set\n",
    "xgb_m3_predictions = xgb_m3_regressor.predict(test_longer[short_features])\n",
    "xgb_m3_predictions = np.maximum(xgb_m3_predictions, 0)\n",
    "\n",
    "# Evaluate\n",
    "mse_m3_xgb = mean_squared_error(y_test, xgb_m3_predictions)\n",
    "print(\"XGBoost MSE:\", mse_m3_xgb)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(mse_m3_xgb))\n",
    "print()\n",
    "\n",
    "# Compare to candidate model\n",
    "final_candidate = mean_squared_error(test['sb_final_best_ln'], test['candidate_sb_best_sum_nokgi_ln1'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Jitter parameters\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Create jittered versions of predictions\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi_ln1']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Extract hover info (assuming these are in the index)\n",
    "month_ids = test.index.get_level_values('month_id') if 'month_id' in test.index.names else test['month_id']\n",
    "c_ids = test.index.get_level_values('c_id') if 'c_id' in test.index.names else test['c_id']\n",
    "hover_text = [f\"month_id: {m}, c_id: {c}\" for m, c in zip(month_ids, c_ids)]\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=[\n",
    "    \"XGBoost: Predicted vs Actual\",\n",
    "    \"XGBoost: Plot with Jitter\",\n",
    "    \"Candidate vs GED Final\",\n",
    "    \"Candidate: Plot with Jitter\"\n",
    "])\n",
    "\n",
    "# 1. XGBoost: Predicted vs Actual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=xgb_m3_predictions,\n",
    "    y=y_test,\n",
    "    mode='markers',\n",
    "    marker=dict(color='crimson', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='XGB'\n",
    "), row=1, col=1)\n",
    "\n",
    "# 2. XGBoost: Jittered\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_jittered_xgb,\n",
    "    y=y_jittered_xgb,\n",
    "    mode='markers',\n",
    "    marker=dict(color='crimson', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='XGB Jitter'\n",
    "), row=1, col=2)\n",
    "\n",
    "# 3. Candidate vs Actual\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=candidate_preds,\n",
    "    y=y_test,\n",
    "    mode='markers',\n",
    "    marker=dict(color='teal', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='Candidate'\n",
    "), row=2, col=1)\n",
    "\n",
    "# 4. Candidate: Jittered\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_jittered_candidate,\n",
    "    y=y_jittered_candidate,\n",
    "    mode='markers',\n",
    "    marker=dict(color='teal', opacity=0.3),\n",
    "    text=hover_text,\n",
    "    hoverinfo='text',\n",
    "    name='Candidate Jitter'\n",
    "), row=2, col=2)\n",
    "\n",
    "# Add 45-degree line to each subplot\n",
    "for row in [1, 2]:\n",
    "    for col in [1, 2]:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[-1, 11],\n",
    "            y=[-1, 11],\n",
    "            mode='lines',\n",
    "            line=dict(color='black', dash='dash'),\n",
    "            showlegend=False\n",
    "        ), row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    width=1000,\n",
    "    title_text=\"Interactive Model Comparison Plots\",\n",
    ")\n",
    "\n",
    "# Set x and y limits for all plots\n",
    "for i in range(1, 5):\n",
    "    fig.update_xaxes(range=[-1, 11], row=(i - 1) // 2 + 1, col=(i - 1) % 2 + 1)\n",
    "    fig.update_yaxes(range=[-1, 11], row=(i - 1) // 2 + 1, col=(i - 1) % 2 + 1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING (2x2 layout)\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Jittered predictions for XGBoost\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Jittered predictions for Candidate Model\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi_ln1']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# 1. XGBoost Predictions vs Actual (Original)\n",
    "ax[0, 0].scatter(xgb_m3_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 0].set_title('XGBoost: Predicted vs Actual')\n",
    "ax[0, 0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 0].set_xlim([-1, 11])\n",
    "ax[0, 0].set_ylim([-1, 11])\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# 2. XGBoost Predictions vs Actual (with Jitter)\n",
    "ax[0, 1].scatter(x_jittered_xgb, y_jittered_xgb, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 1].set_title('XGBoost: Plot with Jitter')\n",
    "ax[0, 1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 1].set_xlim([-1, 11])\n",
    "ax[0, 1].set_ylim([-1, 11])\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# 3. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 0].scatter(test['candidate_sb_best_sum_nokgi_ln1'], y_test, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 0].set_title('Candidate vs GED Final')\n",
    "ax[1, 0].set_xlabel('Candidate Values (Logged)')\n",
    "ax[1, 0].set_ylabel('GED Final Values (Logged)')\n",
    "ax[1, 0].set_xlim([-1, 11])\n",
    "ax[1, 0].set_ylim([-1, 11])\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# 4. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 1].scatter(x_jittered_candidate, y_jittered_candidate, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 1].set_title('Candidate: Plot with Jitter')\n",
    "ax[1, 1].set_xlabel('Candidate Predicted Values (Logged)')\n",
    "ax[1, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1, 1].set_xlim([-1, 11])\n",
    "ax[1, 1].set_ylim([-1, 11])\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Compute residuals and group by c_id\n",
    "test['residual'] = y_test - xgb_m3_predictions\n",
    "resid_by_country = test.groupby('c_id')['residual'].mean().sort_values()\n",
    "\n",
    "# Convert to a DataFrame for Plotly\n",
    "resid_df = resid_by_country.reset_index()\n",
    "resid_df.columns = ['c_id', 'avg_residual']\n",
    "\n",
    "# Create interactive bar plot\n",
    "fig = px.bar(\n",
    "    resid_df,\n",
    "    x='c_id',\n",
    "    y='avg_residual',\n",
    "    title='Average Residual by Country (c_id)',\n",
    "    labels={'c_id': 'Country (c_id)', 'avg_residual': 'Average Residual'},\n",
    "    hover_data={'c_id': True, 'avg_residual': True}\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    height=500,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting these countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(df, c_id):\n",
    "    \"\"\"\n",
    "    Plots actual vs predicted values over month_id for a given c_id.\n",
    "\n",
    "    :param df: DataFrame containing the data\n",
    "    :param c_id: The c_id to filter the data\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the selected c_id\n",
    "    filtered_df = df[df['c_id'] == c_id]\n",
    "\n",
    "    # Set the index to month_id for plotting\n",
    "    filtered_df.set_index('month_id', inplace=True)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(filtered_df['Actual'], color='black', label='Actuals')\n",
    "    plt.plot(filtered_df['Predicted'], color='#FF6700', linestyle='dashed', label='Predictions')\n",
    "    plt.plot(filtered_df['sb_candidate_ln'], color='#800080', linestyle='dashed', label='Candidate')\n",
    "    plt.plot(filtered_df['acled_sb_fat_ln'], color='#008000', alpha=0.3, label='ACLED')\n",
    "\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Month ID')\n",
    "    plt.ylabel('Fatlities (Logged)')\n",
    "    plt.title(f'Actual vs Predicted Fatalities for c_id: {c_id}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to ensure c_id and month_id are available as columns\n",
    "df_results = test_longer.reset_index().copy()\n",
    "\n",
    "# Keep only necessary columns\n",
    "df_results = df_results[['c_id', 'month_id']]\n",
    "\n",
    "# Add predictions and actual values\n",
    "df_results['Actual'] = y_test.values  # Ensure alignment\n",
    "df_results['Predicted'] = xgb_m3_predictions\n",
    "\n",
    "# Check if 'candidate_sb_best_sum_nokgi_ln1' exists in test, otherwise assign NaN\n",
    "if 'candidate_sb_best_sum_nokgi_ln1' in test_longer.columns:\n",
    "    df_results['sb_candidate_ln'] = test_longer.reset_index()['candidate_sb_best_sum_nokgi_ln1']\n",
    "else:\n",
    "    df_results['sb_candidate_ln'] = np.nan\n",
    "\n",
    "# Check if 'acled_sb_fat_ln' exists in test, otherwise assign NaN\n",
    "if 'acled_sb_fat_ln' in test_longer.columns:\n",
    "    df_results['acled_sb_fat_ln'] = test_longer.reset_index()['acled_sb_fat_ln']\n",
    "else:\n",
    "    df_results['acled_sb_fat_ln'] = np.nan\n",
    "\n",
    "# Save to CSV\n",
    "df_results.to_csv(\"xgb_predictions_vs_actuals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df_results.copy()\n",
    "plot_df = plot_df.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the plots will be saved\n",
    "save_dir = \"/Users/chandlerwilliams/Desktop/views_projects/nowcasting/nowcasting/country_plots/\"\n",
    "\n",
    "# Loop through values from 1 to 246\n",
    "for i in range(1, 247):\n",
    "    try:\n",
    "        plt.figure()  # Start a new figure\n",
    "        plot_actual_vs_predicted(plot_df, i)  # Generate the plot\n",
    "        save_path = os.path.join(save_dir, f\"country_plot_{i}.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')  # Save the plot\n",
    "        plt.close()  # Free up memory\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {i} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted_save(df, i):\n",
    "    fig, ax = plt.subplots()\n",
    "    subset = df[df['id'] == i]  # Or whatever filtering logic\n",
    "    if subset.empty:\n",
    "        return None  # Skip if there's no data\n",
    "    \n",
    "    ax.plot(subset['x'], subset['actual'], label='Actual')\n",
    "    ax.plot(subset['x'], subset['predicted'], label='Predicted')\n",
    "    ax.set_title(f\"Actual vs. Predicted for ID {i}\")\n",
    "    ax.legend()\n",
    "    return fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_vs_predicted(plot_df, 218) # Isreal\n",
    "plot_actual_vs_predicted(plot_df, 47) # Burkina Faso\n",
    "plot_actual_vs_predicted(plot_df, 245) # Sudan\n",
    "plot_actual_vs_predicted(plot_df, 57) # Ethiopia\n",
    "plot_actual_vs_predicted(plot_df, 4) # Venezuela\n",
    "plot_actual_vs_predicted(plot_df, 237) # Kenya\n",
    "\n",
    "plot_actual_vs_predicted(plot_df, 246) # \n",
    "plot_actual_vs_predicted(plot_df, 172) #\n",
    "plot_actual_vs_predicted(plot_df, 17) # \n",
    "plot_actual_vs_predicted(plot_df, 78) # Niger\n",
    "\n",
    "\n",
    "plot_actual_vs_predicted(plot_df, 117) # ukraine\n",
    "plot_actual_vs_predicted(plot_df, 79) # ukraine\n",
    "plot_actual_vs_predicted(plot_df, 137) # Tahjikistan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying the non-logged versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nowcasting_master_final_data_1.csv', index_col=(['month_id','c_id']))\n",
    "\n",
    "# drop source_version\n",
    "df.drop('source_version', axis=1, inplace=True)\n",
    "\n",
    "# Training set uses data from 2018 until 2022\n",
    "train = df.loc[(df['year'] >= 2018) & (df['year'] < 2023)]\n",
    "\n",
    "# Test set uses 2022\n",
    "test = df.loc[(df['year'] > 2022)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test Labels\n",
    "y_train = train['sb_final_best']\n",
    "y_test = test['sb_final_best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [\n",
    "    'AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', \n",
    "    'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', \n",
    "    'BRA', 'BRB', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', \n",
    "    'COD', 'COG', 'COL', 'COM', 'CRI', 'CUB', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', \n",
    "    'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', \n",
    "    'FRA', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', \n",
    "    'GTM', 'GUY', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', \n",
    "    'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KOR', \n",
    "    'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LKA', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', \n",
    "    'MDG', 'MDV', 'MEX', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', \n",
    "    'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', \n",
    "    'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PNG', 'POL', 'PRK', 'PRT', 'PRY', 'QAT', \n",
    "    'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLE', 'SLV', 'SOM', 'SRB', \n",
    "    'SSD', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', \n",
    "    'TKM', 'TLS', 'TTO', 'TUN', 'TUR', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', \n",
    "    'UZB', 'VEN', 'VNM', 'YEM', 'ZAF', 'ZMB', 'ZWE']   \n",
    " \n",
    "short_features = ['acled_sb_fat', 'acled_sb_count', 'acled_ns_fat', 'acled_ns_count', 'acled_os_fat', 'acled_os_count', 'acled_pr_count','month','topic_conflict_1',\n",
    " 'topic_judiciary_1', 'topic_diplomacy_1', 'vdem_v2x_delibdem', 'vdem_v2x_clphy', 'vdem_v2x_rule', 'vdem_v2x_freexp', 'candidate_sb_best_sum_nokgi',\n",
    " 'candidate_ns_best_sum_nokgi',\n",
    " 'candidate_os_best_sum_nokgi',\n",
    " 'candidate_sb_best_count_nokgi',\n",
    " 'candidate_ns_best_count_nokgi',\n",
    " 'candidate_os_best_count_nokgi',\n",
    " 'candidate_sb_high_sum_nokgi',\n",
    " 'candidate_ns_high_sum_nokgi',\n",
    " 'candidate_os_high_sum_nokgi',\n",
    " 'candidate_sb_high_count_nokgi',\n",
    " 'candidate_ns_high_count_nokgi',\n",
    " 'candidate_os_high_count_nokgi',] \n",
    "\n",
    "short_list = short_features + countries\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "train_nonlog = train[short_list]\n",
    "test_nonlog = test[short_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBRegressor model\n",
    "\n",
    "xgb_m3_regressor = xgb.XGBRegressor(eval_metric='rmse',\n",
    "                                       learning_rate = 0.02,\n",
    "                                       max_depth = 10,\n",
    "                                       n_estimators = 500,\n",
    "                                       colsample_bytree = 0.6,\n",
    "                                       subsample = 0.8,\n",
    "                                       #reg_alpha = 0.4,\n",
    "                                       #reg_lambda =0.4,\n",
    "                                       random_state = 17\n",
    "                                      ) \n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "xgb_m3_regressor.fit(train_nonlog, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_m3_predictions = xgb_m3_regressor.predict(test_nonlog)\n",
    "\n",
    "xgb_m3_predictions = np.maximum(xgb_m3_predictions, 0)\n",
    "\n",
    "# Evaluate the model using MSE or any other suitable regression metric\n",
    "mse_m3_xgb = mean_squared_error(y_test, xgb_m3_predictions)\n",
    "print(\"XGBoost MSE:\", mse_m3_xgb)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(mse_m3_xgb))\n",
    "print(' ')\n",
    "final_candidate = mean_squared_error(test['sb_final_best'], test['candidate_sb_best_sum_nokgi'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "## PLOTTING (2x2 layout)\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Jittered predictions for XGBoost\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Jittered predictions for Candidate Model\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# 1. XGBoost Predictions vs Actual (Original)\n",
    "ax[0, 0].scatter(xgb_m3_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 0].set_title('XGBoost: Predicted vs Actual')\n",
    "ax[0, 0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# 2. XGBoost Predictions vs Actual (with Jitter)\n",
    "ax[0, 1].scatter(x_jittered_xgb, y_jittered_xgb, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 1].set_title('XGBoost: Plot with Jitter')\n",
    "ax[0, 1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# 3. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 0].scatter(test['candidate_sb_best_sum_nokgi'], y_test, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 0].set_title('Candidate vs GED Final')\n",
    "ax[1, 0].set_xlabel('Candidate Values (Logged)')\n",
    "ax[1, 0].set_ylabel('GED Final Values (Logged)')\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# 4. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 1].scatter(x_jittered_candidate, y_jittered_candidate, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 1].set_title('Candidate: Plot with Jitter')\n",
    "ax[1, 1].set_xlabel('Candidate Predicted Values (Logged)')\n",
    "ax[1, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# EVAL METRICS\n",
    "# Assuming your RandomForest model is named 'rf_best' and is already trained\n",
    "feature_importances_xgb = xgb_m3_regressor.feature_importances_\n",
    "\n",
    "# Assuming 'X_train' is your training dataset\n",
    "feature_names_xgb = train_nonlog.columns\n",
    "\n",
    "# Create a pandas DataFrame for easier visualization\n",
    "feature_importance_xgb = pd.DataFrame({'Feature': feature_names_xgb, 'Importance': feature_importances_xgb})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "feature_importance_xgb = feature_importance_xgb.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance scores\n",
    "feature_importance_xgb.head(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the model for non-logged predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Set up time-based cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Define your base model structure\n",
    "xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    booster='gbtree',\n",
    "    random_state=17\n",
    ")\n",
    "\n",
    "# Define the parameter grid around your original values\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.02, 0.05],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'n_estimators': [250, 500],\n",
    "    'colsample_bytree': [0.6, 0.8],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 5],\n",
    "    # Uncomment to tune regularization too:\n",
    "    # 'reg_alpha': [0, 0.4],\n",
    "    # 'reg_lambda': [0, 0.4, 1.0],\n",
    "}\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',  \n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run the grid search\n",
    "grid_search.fit(train_nonlog, y_train)\n",
    "\n",
    "# Print best results\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best RMSE score:\", np.sqrt(-grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBRegressor model\n",
    "\n",
    "xgb_m3_regressor = xgb.XGBRegressor(eval_metric='rmse',\n",
    "                                       learning_rate = 0.01,\n",
    "                                       max_depth = 3,\n",
    "                                       n_estimators = 1000,\n",
    "                                       colsample_bytree = 0.6,\n",
    "                                       subsample = 0.8,\n",
    "                                       #reg_alpha = 0.4,\n",
    "                                       #reg_lambda =0.4,\n",
    "                                       random_state = 17\n",
    "                                      ) \n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "xgb_m3_regressor.fit(train_nonlog, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_m3_predictions = xgb_m3_regressor.predict(test_nonlog)\n",
    "\n",
    "xgb_m3_predictions = np.maximum(xgb_m3_predictions, 0)\n",
    "\n",
    "# Evaluate the model using MSE or any other suitable regression metric\n",
    "mse_m3_xgb = mean_squared_error(y_test, xgb_m3_predictions)\n",
    "print(\"XGBoost MSE:\", mse_m3_xgb)\n",
    "print(\"XGBoost RMSE:\", np.sqrt(mse_m3_xgb))\n",
    "print(' ')\n",
    "final_candidate = mean_squared_error(test['sb_final_best'], test['candidate_sb_best_sum_nokgi'])\n",
    "print('MSE GED Final vs UCDP Candidate:', final_candidate)\n",
    "print('RMSE GED Final vs UCDP Candidate:', np.sqrt(final_candidate))\n",
    "\n",
    "## PLOTTING (2x2 layout)\n",
    "# Parameters for jitter\n",
    "jitter_amount = 0.15\n",
    "\n",
    "# Jittered predictions for XGBoost\n",
    "x_jittered_xgb = xgb_m3_predictions + np.random.normal(0, jitter_amount, size=len(xgb_m3_predictions))\n",
    "y_jittered_xgb = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Jittered predictions for Candidate Model\n",
    "candidate_preds = test['candidate_sb_best_sum_nokgi']\n",
    "x_jittered_candidate = candidate_preds + np.random.normal(0, jitter_amount, size=len(candidate_preds))\n",
    "y_jittered_candidate = y_test + np.random.normal(0, jitter_amount, size=len(y_test))\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, ax = plt.subplots(2, 2, figsize=(16, 16))\n",
    "\n",
    "# 1. XGBoost Predictions vs Actual (Original)\n",
    "ax[0, 0].scatter(xgb_m3_predictions, y_test, alpha=0.3, color='crimson', linewidth=1, s=30)\n",
    "ax[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 0].set_title('XGBoost: Predicted vs Actual')\n",
    "ax[0, 0].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 0].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 0].grid(True)\n",
    "\n",
    "# 2. XGBoost Predictions vs Actual (with Jitter)\n",
    "ax[0, 1].scatter(x_jittered_xgb, y_jittered_xgb, alpha=0.3, color='crimson', marker='o', linewidth=1, s=30)\n",
    "ax[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[0, 1].set_title('XGBoost: Plot with Jitter')\n",
    "ax[0, 1].set_xlabel('Predicted Values (Logged)')\n",
    "ax[0, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[0, 1].grid(True)\n",
    "\n",
    "# 3. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 0].scatter(test['candidate_sb_best_sum_nokgi'], y_test, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 0].set_title('Candidate vs GED Final')\n",
    "ax[1, 0].set_xlabel('Candidate Values (Logged)')\n",
    "ax[1, 0].set_ylabel('GED Final Values (Logged)')\n",
    "ax[1, 0].grid(True)\n",
    "\n",
    "# 4. Candidate Predictions vs Actual (with Jitter)\n",
    "ax[1, 1].scatter(x_jittered_candidate, y_jittered_candidate, alpha=0.3, color='teal', marker='o', linewidth=1, s=30)\n",
    "ax[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "ax[1, 1].set_title('Candidate: Plot with Jitter')\n",
    "ax[1, 1].set_xlabel('Candidate Predicted Values (Logged)')\n",
    "ax[1, 1].set_ylabel('Actual Values (Logged)')\n",
    "ax[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# EVAL METRICS\n",
    "# Assuming your RandomForest model is named 'rf_best' and is already trained\n",
    "feature_importances_xgb = xgb_m3_regressor.feature_importances_\n",
    "\n",
    "# Assuming 'X_train' is your training dataset\n",
    "feature_names_xgb = train_nonlog.columns\n",
    "\n",
    "# Create a pandas DataFrame for easier visualization\n",
    "feature_importance_xgb = pd.DataFrame({'Feature': feature_names_xgb, 'Importance': feature_importances_xgb})\n",
    "\n",
    "# Sort the DataFrame to show the most important features at the top\n",
    "feature_importance_xgb = feature_importance_xgb.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance scores\n",
    "feature_importance_xgb.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(df, c_id):\n",
    "    \"\"\"\n",
    "    Plots actual vs predicted values over month_id for a given c_id.\n",
    "\n",
    "    :param df: DataFrame containing the data\n",
    "    :param c_id: The c_id to filter the data\n",
    "    \"\"\"\n",
    "    # Filter the DataFrame for the selected c_id\n",
    "    filtered_df = df[df['c_id'] == c_id]\n",
    "\n",
    "    # Set the index to month_id for plotting\n",
    "    filtered_df.set_index('month_id', inplace=True)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(filtered_df['Actual'], color='black', label='Actuals')\n",
    "    plt.plot(filtered_df['Predicted'], color='#FF6700', linestyle='dashed', label='Predictions')\n",
    "    plt.plot(filtered_df['candidate_sb_best_sum_nokgi'], color='#800080', linestyle='dashed', label='Candidate')\n",
    "    plt.plot(filtered_df['acled_sb_fat'], color='#008000', alpha=0.3, label='ACLED')\n",
    "\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Month ID')\n",
    "    plt.ylabel('Fatlities (Logged)')\n",
    "    plt.title(f'Actual vs Predicted Fatalities for c_id: {c_id}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to ensure c_id and month_id are available as columns\n",
    "df_results = test_nonlog.reset_index().copy()\n",
    "\n",
    "# Keep only necessary columns\n",
    "df_results = df_results[['c_id', 'month_id']]\n",
    "\n",
    "# Add predictions and actual values\n",
    "df_results['Actual'] = y_test.values  # Ensure alignment\n",
    "df_results['Predicted'] = xgb_m3_predictions\n",
    "\n",
    "# Check if 'candidate_sb_best_sum_nokgi_ln1' exists in test, otherwise assign NaN\n",
    "if 'candidate_sb_best_sum_nokgi' in test.columns:\n",
    "    df_results['candidate_sb_best_sum_nokgi'] = test.reset_index()['candidate_sb_best_sum_nokgi']\n",
    "else:\n",
    "    df_results['candidate_sb_best_sum_nokgi'] = np.nan\n",
    "\n",
    "# Check if 'acled_sb_fat_ln' exists in test, otherwise assign NaN\n",
    "if 'acled_sb_fat' in test_nonlog.columns:\n",
    "    df_results['acled_sb_fat'] = test_nonlog.reset_index()['acled_sb_fat']\n",
    "else:\n",
    "    df_results['acled_sb_fat'] = np.nan\n",
    "\n",
    "# Save to CSV\n",
    "df_results.to_csv(\"xgb_predictions_vs_actuals.csv\", index=False)\n",
    "\n",
    "plot_df = df_results.copy()\n",
    "plot_df = plot_df.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_vs_predicted(plot_df, 218) # Isreal\n",
    "plot_actual_vs_predicted(plot_df, 47) # Burkina Faso\n",
    "plot_actual_vs_predicted(plot_df, 245) # Sudan\n",
    "plot_actual_vs_predicted(plot_df, 57) # Ethiopia\n",
    "plot_actual_vs_predicted(plot_df, 4) # Venezuela\n",
    "plot_actual_vs_predicted(plot_df, 237) # Kenya\n",
    "\n",
    "plot_actual_vs_predicted(plot_df, 246) # \n",
    "plot_actual_vs_predicted(plot_df, 172) #\n",
    "plot_actual_vs_predicted(plot_df, 17) # \n",
    "plot_actual_vs_predicted(plot_df, 78) # Niger\n",
    "\n",
    "\n",
    "plot_actual_vs_predicted(plot_df, 117) # ukraine\n",
    "plot_actual_vs_predicted(plot_df, 79) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_train, bins=100)\n",
    "plt.title('Distribution of Raw Target Values')\n",
    "plt.xlabel('Fatalities')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')  # helpful if there's a long tail\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
