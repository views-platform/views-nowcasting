{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all UCDP Candidate Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from ingester3.extensions import *\n",
    "from ingester3.DBWriter import DBWriter\n",
    "from ingester3.scratch import cache_manager\n",
    "from ingester3.config import source_db_path\n",
    "from diskcache import Cache\n",
    "\n",
    "\n",
    "# This cell imports the basic packages needed to run the notebook \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pdx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import tabula\n",
    "import xlwings as xw\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "#import views_dataviz\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "\n",
    "# VIEWS mapper2\n",
    "#from views_mapper2.label_writer import *\n",
    "\n",
    "# Ingester\n",
    "from ingester3.config import source_db_path\n",
    "from ingester3.Country import Country\n",
    "from ingester3.extensions import *\n",
    "from ingester3.ViewsMonth import ViewsMonth\n",
    "from ingester3.DBWriter import DBWriter\n",
    "from ingester3.scratch import cache_manager\n",
    "cache_manager()\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "\n",
    "import os\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "\n",
    "##################\n",
    "print('OS Login is:', os.getlogin())\n",
    "print('OS path is set to:', home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ged_cache = Cache('ged_x.cache')\n",
    "ged_cache.clear(retry=True)\n",
    "\n",
    "\n",
    "class GedLoader:\n",
    "    def __init__(self,version,verbose=True, no_val=None):\n",
    "        \n",
    "        cache_manager()\n",
    "        self.version = version\n",
    "        self.ged = None\n",
    "        \n",
    "        self.ged_agg_pgm = None\n",
    "        self.ged_agg_cm = None\n",
    "\n",
    "        if no_val is None: \n",
    "            self.no_val = []\n",
    "        else:\n",
    "            self.no_val = [i.lower() for i in no_val]\n",
    "            \n",
    "        self.__get_month_id()\n",
    "        \n",
    "        self.verbose_print = print if verbose else lambda *a, **k: None\n",
    "\n",
    "        \n",
    "    def __get_month_id(self):\n",
    "        \"\"\"\n",
    "        If trying to load a GED Candidates dataset (20.0.x) infer what ViEWS MonthID it refers to.\n",
    "        Return nothing otherwise\n",
    "        \"\"\"\n",
    "        self.month_id = None\n",
    "        if self.version.count('.')==2:\n",
    "            year_extent=int('20'+self.version.split('.')[0])\n",
    "            month_extent=int(self.version.split('.')[2])\n",
    "            self.month_id = ViewsMonth.from_year_month(year_extent,month_extent)\n",
    "    \n",
    "    @staticmethod\n",
    "    @ged_cache.memoize(typed=True, expire=600000, tag='ged_slice') \n",
    "    def _get_ged_slice(next_page_url, token=None):\n",
    "        headers = {'x-ucdp-access-token': token}\n",
    "        r = requests.get(next_page_url, headers=headers)\n",
    "        output = r.json()\n",
    "        next_page_url = output['NextPageUrl'] if output['NextPageUrl'] != '' else None\n",
    "        ged = pd.DataFrame(output['Result'])\n",
    "        page_count = output['TotalPages']\n",
    "        return next_page_url, ged, page_count\n",
    "    \n",
    "    def fetch_ged(self, pagesize=50000):\n",
    "        cur_page = 1\n",
    "        next_page_url = f\"https://ucdpapi.pcr.uu.se/api/gedevents/{self.version}?pagesize={pagesize}&page=0\"\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        while next_page_url:\n",
    "            print(next_page_url)\n",
    "            next_page_url, ged_slice, total_pages = self._get_ged_slice(\\\n",
    "                next_page_url=next_page_url, token=\"48dda3460c347f3b\"\\\n",
    "            )\n",
    "            df = pd.concat([df,ged_slice], ignore_index=True)\n",
    "            print(f\"{cur_page} of {total_pages} pages loaded.\")\n",
    "            #cur_page += 1\n",
    "            \n",
    "            if cur_page > total_pages:\n",
    "                ged_cache.clear(retry=True)\n",
    "                raise ConnectionError('The UCDP API is misbehaving. Try again later!')\n",
    "            cur_page += 1\n",
    "            \n",
    "\n",
    "        self.ged = df\n",
    "        \n",
    "    def filter_ged(self):\n",
    "        self.ged = self.ged[self.ged.priogrid_gid>=1]\n",
    "        self.ged.date_end = pd.to_datetime(self.ged.date_end)\n",
    "        self.ged = pd.DataFrame.pgm.from_datetime(self.ged,'date_end').rename(columns = {'priogrid_gid':'pg_id',\n",
    "                                                                       'type_of_violence':'tv'})\n",
    "        self.ged = self.ged[self.ged.tv<4]\n",
    "        self.pg_ged = self.ged[(self.ged.where_prec != 4) & (self.ged.where_prec != 6)]\n",
    "        \n",
    "    def aggregate_to_pg(self):\n",
    "        \"\"\"\n",
    "        Aggregate GED to Priogrid level.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Group by type of violence, priogrid id and month id\n",
    "        #Aggregate to PG, taking sum and count\n",
    "        ged_fraction = self.pg_ged[['tv','pg_id','month_id','best','high']]\n",
    "        ged_agg = ged_fraction.groupby(by=['tv','pg_id','month_id']).aggregate(['sum','count'])\n",
    "        \n",
    "        #Eliminate the double-index nesting that resulted from the aggregation process\n",
    "        ged_agg['best_sum'] = ged_agg['best']['sum']\n",
    "        ged_agg['best_count'] = ged_agg['best']['count']\n",
    "        ged_agg['high_sum'] = ged_agg['high']['sum']\n",
    "        ged_agg['high_count'] = ged_agg['high']['count']\n",
    "        del ged_agg['best']\n",
    "        del ged_agg['high']\n",
    "        \n",
    "        #Reset the index\n",
    "        ged_agg = ged_agg.reset_index()\n",
    "        \n",
    "        #Pivot the long-form to a wide-form required by the database\n",
    "        #You don't need to fill in the panel because the DB will automate the infill.\n",
    "        ged_pivot = ged_agg.pivot(index=['pg_id','month_id'], \n",
    "              columns=['tv'],\n",
    "              values = ['best_sum','best_count','high_sum','high_count']).fillna(0).astype('int64')\n",
    "        \n",
    "        #The pivot will produce a multi-level columnar structure\n",
    "        #Flatten this to column names that we will be using in the DB.\n",
    "        \n",
    "        ged_pivot['ged_sb_best_sum_nokgi'] = ged_pivot['best_sum'][1]\n",
    "        ged_pivot['ged_ns_best_sum_nokgi'] = ged_pivot['best_sum'][2]\n",
    "        ged_pivot['ged_os_best_sum_nokgi'] = ged_pivot['best_sum'][3]\n",
    "\n",
    "        ged_pivot['ged_sb_best_count_nokgi'] = ged_pivot['best_count'][1]\n",
    "        ged_pivot['ged_ns_best_count_nokgi'] = ged_pivot['best_count'][2]\n",
    "        ged_pivot['ged_os_best_count_nokgi'] = ged_pivot['best_count'][3]\n",
    "\n",
    "        ged_pivot['ged_sb_high_sum_nokgi'] = ged_pivot['high_sum'][1]\n",
    "        ged_pivot['ged_ns_high_sum_nokgi'] = ged_pivot['high_sum'][2]\n",
    "        ged_pivot['ged_os_high_sum_nokgi'] = ged_pivot['high_sum'][3]\n",
    "\n",
    "        ged_pivot['ged_sb_high_count_nokgi'] = ged_pivot['high_count'][1]\n",
    "        ged_pivot['ged_ns_high_count_nokgi'] = ged_pivot['high_count'][2]\n",
    "        ged_pivot['ged_os_high_count_nokgi'] = ged_pivot['high_count'][3]\n",
    "\n",
    "        del(ged_pivot['best_count'])\n",
    "        del(ged_pivot['high_count'])\n",
    "        del(ged_pivot['best_sum'])\n",
    "        del(ged_pivot['high_sum'])\n",
    "        \n",
    "        #Simplify everything by removing the multi-level columnar structure.\n",
    "        ged_pivot = ged_pivot.reset_index()\n",
    "        ged_pivot.columns = ged_pivot.columns.droplevel(1)\n",
    "        \n",
    "        self.ged_agg_pgm = ged_pivot\n",
    "        return self.ged_agg_pgm\n",
    "    \n",
    "    \n",
    "    def aggregate_to_cm(self):\n",
    "        \n",
    "        ged_cm_agg = self.ged[['tv','country_id','month_id','best','high']].\\\n",
    "        groupby(by=['tv','country_id','month_id']).aggregate(['sum','count'])\n",
    "\n",
    "        ged_cm_agg['best_sum'] = ged_cm_agg['best']['sum']\n",
    "        ged_cm_agg['best_count'] = ged_cm_agg['best']['count']\n",
    "        ged_cm_agg['high_sum'] = ged_cm_agg['high']['sum']\n",
    "        ged_cm_agg['high_count'] = ged_cm_agg['high']['count']\n",
    "\n",
    "        del ged_cm_agg['best']\n",
    "        del ged_cm_agg['high']\n",
    "\n",
    "        ged_cm_agg = ged_cm_agg.reset_index()\n",
    "        \n",
    "        # GED is sometimes faulty in terms of what countries and months it contains.\n",
    "        # We need to filter out the not working data.\n",
    "        \n",
    "        ged_cm_agg = pd.DataFrame.cm.soft_validate_gwcode(ged_cm_agg,'country_id','month_id')\n",
    "        ged_cm_agg = ged_cm_agg[ged_cm_agg.valid_id==True]\n",
    "        \n",
    "        ged_cm_agg = pd.DataFrame.cm.from_gwcode(ged_cm_agg, \n",
    "                                                 gw_col='country_id', \n",
    "                                                 month_col='month_id')\n",
    "\n",
    "        ged_cm_agg.columns = ged_cm_agg.columns.droplevel(1)\n",
    "        del ged_cm_agg['country_id']\n",
    "        \n",
    "        ged_cm_pivot = ged_cm_agg.pivot(index=['c_id','month_id'], \n",
    "                                columns=['tv'],\n",
    "                                values = ['best_sum','best_count',\n",
    "                                          'high_sum','high_count']).fillna(0).astype('int64')\n",
    "        \n",
    "        ged_cm_pivot['ged_sb_best_sum_nokgi'] = ged_cm_pivot['best_sum'][1]\n",
    "        ged_cm_pivot['ged_ns_best_sum_nokgi'] = ged_cm_pivot['best_sum'][2]\n",
    "        ged_cm_pivot['ged_os_best_sum_nokgi'] = ged_cm_pivot['best_sum'][3]\n",
    "\n",
    "        ged_cm_pivot['ged_sb_best_count_nokgi'] = ged_cm_pivot['best_count'][1]\n",
    "        ged_cm_pivot['ged_ns_best_count_nokgi'] = ged_cm_pivot['best_count'][2]\n",
    "        ged_cm_pivot['ged_os_best_count_nokgi'] = ged_cm_pivot['best_count'][3]\n",
    "        \n",
    "        ged_cm_pivot['ged_sb_high_sum_nokgi'] = ged_cm_pivot['high_sum'][1]\n",
    "        ged_cm_pivot['ged_ns_high_sum_nokgi'] = ged_cm_pivot['high_sum'][2]\n",
    "        ged_cm_pivot['ged_os_high_sum_nokgi'] = ged_cm_pivot['high_sum'][3]\n",
    "\n",
    "        ged_cm_pivot['ged_sb_high_count_nokgi'] = ged_cm_pivot['high_count'][1]\n",
    "        ged_cm_pivot['ged_ns_high_count_nokgi'] = ged_cm_pivot['high_count'][2]\n",
    "        ged_cm_pivot['ged_os_high_count_nokgi'] = ged_cm_pivot['high_count'][3]\n",
    "\n",
    "        del(ged_cm_pivot['best_count'])\n",
    "        del(ged_cm_pivot['high_count'])\n",
    "        del(ged_cm_pivot['best_sum'])\n",
    "        del(ged_cm_pivot['high_sum'])\n",
    "\n",
    "        ged_cm_pivot = ged_cm_pivot.reset_index()\n",
    "        ged_cm_pivot.columns = ged_cm_pivot.columns.droplevel(1)\n",
    "        \n",
    "        self.ged_agg_cm = ged_cm_pivot\n",
    "        return self.ged_agg_cm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of all the GED Candidate Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GED_VERSIONS = [\n",
    "    \"18.0.1\", \"18.0.2\", \"18.0.3\", \"18.0.4\", \"18.0.5\", \"18.0.6\",\n",
    "    \"18.0.7\", \"18.0.8\", \"18.0.9\", \"18.0.10\", \"18.0.11\", \"18.0.12\",\n",
    "    \"19.0.1\", \"19.0.2\", \"19.0.3\", \"19.0.4\", \"19.0.5\", \"19.0.6\",\n",
    "    \"19.0.7\", \"19.0.8\", \"19.0.9\", \"19.0.10\", \"19.0.11\", \"19.0.12\",\n",
    "    \"20.0.1\", \"20.0.2\", \"20.0.3\", \"20.0.4\", \"20.0.5\", \"20.0.6\",\n",
    "    \"20.0.7\", \"20.0.8\", \"20.0.9\", \"20.0.10\", \"20.0.11\", \"20.0.12\",\n",
    "    \"21.0.1\", \"21.0.2\", \"21.0.3\", \"21.0.4\", \"21.0.5\", \"21.0.6\",\n",
    "    \"21.0.7\", \"21.0.8\", \"21.0.9\", \"21.0.10\", \"21.0.11\", \"21.0.12\",\n",
    "    \"22.0.1\", \"22.0.2\", \"22.0.3\", \"22.0.4\", \"22.0.5\", \"22.0.6\",\n",
    "    \"22.0.7\", \"22.0.8\", \"22.0.9\", \"22.0.10\", \"22.0.11\", \"22.0.12\",\n",
    "    \"23.0.1\", \"23.0.2\", \"23.0.3\", \"23.0.4\", \"23.0.5\", \"23.0.6\",\n",
    "    \"23.0.7\", \"23.0.8\", \"23.0.9\", \"23.0.10\", \"23.0.11\", \"23.0.12\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather all the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2, account for data issue in the version 21.0.05\n",
    "\n",
    "# Loop through each GED version\n",
    "for version in GED_VERSIONS:\n",
    "    print(f\"\\n Processing GED Version: {version}\")\n",
    "\n",
    "    # Initialize the loader\n",
    "    loader = GedLoader(version)\n",
    "\n",
    "    # Fetch and filter data\n",
    "    loader.fetch_ged()\n",
    "    loader.filter_ged()\n",
    "\n",
    "    # Aggregate data\n",
    "    pg_df = loader.aggregate_to_pg()\n",
    "    cm_df = loader.aggregate_to_cm()\n",
    "\n",
    "    # Special handling for version '21.0.5'\n",
    "    if version == '21.0.5':\n",
    "        pg_df_filtered = pg_df[pg_df[\"month_id\"] == 497]\n",
    "        cm_df_filtered = cm_df[cm_df[\"month_id\"] == 497]\n",
    "    else:\n",
    "        # Find the most common `month_id` for both datasets\n",
    "        most_common_month_pg = pg_df[\"month_id\"].mode()[0]  # Priogrid\n",
    "        most_common_month_cm = cm_df[\"month_id\"].mode()[0]  # Country-Month\n",
    "\n",
    "        # Filter to keep only rows with the most common `month_id`\n",
    "        pg_df_filtered = pg_df[pg_df[\"month_id\"] == most_common_month_pg]\n",
    "        cm_df_filtered = cm_df[cm_df[\"month_id\"] == most_common_month_cm]\n",
    "\n",
    "    # Save filtered datasets\n",
    "    pg_df_filtered.to_csv(f\"candidate_{version.replace('.', '_')}_pgm.csv\", index=False)\n",
    "    cm_df_filtered.to_csv(f\"candidate_{version.replace('.', '_')}_cm.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved: candidate_{version.replace('.', '_')}_pgm.csv ({len(pg_df_filtered)} rows)\")\n",
    "    print(f\"Saved: candidate_{version.replace('.', '_')}_cm.csv ({len(cm_df_filtered)} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each GED version\n",
    "for version in GED_VERSIONS:\n",
    "    print(f\"\\n Processing GED Version: {version}\")\n",
    "\n",
    "    # Initialize the loader\n",
    "    loader = GedLoader(version)\n",
    "\n",
    "    # Fetch and filter data\n",
    "    loader.fetch_ged()\n",
    "    loader.filter_ged()\n",
    "\n",
    "    # Aggregate data\n",
    "    pg_df = loader.aggregate_to_pg()\n",
    "    cm_df = loader.aggregate_to_cm()\n",
    "\n",
    "    # Find the most common `month_id` for both datasets\n",
    "    most_common_month_pg = pg_df[\"month_id\"].mode()[0]  # Priogrid\n",
    "    most_common_month_cm = cm_df[\"month_id\"].mode()[0]  # Country-Month\n",
    "\n",
    "    # Filter to keep only rows with the most common `month_id`\n",
    "    pg_df_filtered = pg_df[pg_df[\"month_id\"] == most_common_month_pg]\n",
    "    cm_df_filtered = cm_df[cm_df[\"month_id\"] == most_common_month_cm]\n",
    "\n",
    "    # Save filtered datasets\n",
    "    pg_df_filtered.to_csv(f\"candidate_{version.replace('.', '_')}_pgm_filtered.csv\", index=False)\n",
    "    cm_df_filtered.to_csv(f\"candidate_{version.replace('.', '_')}_cm_filtered.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved: candidate_{version.replace('.', '_')}_pgm_filtered.csv ({len(pg_df_filtered)} rows)\")\n",
    "    print(f\"Saved: candidate_{version.replace('.', '_')}_cm_filtered.csv ({len(cm_df_filtered)} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all CM filtered CSV files\n",
    "cm_files = glob.glob(\"candidate_*_cm.csv\")\n",
    "\n",
    "# List to store dataframes\n",
    "df_list = []\n",
    "\n",
    "# Load each CM file and append it to the list\n",
    "for file in cm_files:\n",
    "    print(f\"Loading: {file}\")\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"source_version\"] = file  # Add a column to track the source file\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame\n",
    "combined_df.to_csv(\"candidates_all.csv\", index=False)\n",
    "\n",
    "print(f\"Combined DataFrame saved: candidate_combined_cm.csv ({len(combined_df)} rows)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 'ged_sb_best_sum_nokgi' to 'candidate_sb_best' \n",
    "combined_df.rename(columns={'ged_sb_best_sum_nokgi':'candidate_sb_best'}, inplace=True)\n",
    "\n",
    "# rename 'ged_ns_best_sum_nokgi' to 'candidate_ns_best'\n",
    "combined_df.rename(columns={'ged_ns_best_sum_nokgi':'candidate_ns_best'}, inplace=True)\n",
    "\n",
    "# rename 'ged_os_best_sum_nokgi' to 'candidate_os_best'\n",
    "combined_df.rename(columns={'ged_os_best_sum_nokgi':'candidate_os_best'}, inplace=True)\n",
    "\n",
    "# rename 'ged_sb_high_sum_nokgi' to 'candidate_sb_high'\n",
    "combined_df.rename(columns={'ged_sb_high_sum_nokgi':'candidate_sb_high'}, inplace=True)\n",
    "\n",
    "# rename 'ged_ns_high_sum_nokgi' to 'candidate_ns_high'\n",
    "combined_df.rename(columns={'ged_ns_high_sum_nokgi':'candidate_ns_high'}, inplace=True)\n",
    "\n",
    "# rename 'ged_os_high_sum_nokgi' to 'candidate_os_high'\n",
    "combined_df.rename(columns={'ged_os_high_sum_nokgi':'candidate_os_high'}, inplace=True)\n",
    "\n",
    "# rename 'ged_sb_best_count_nokgi' to 'candidate_sb_count'\n",
    "combined_df.rename(columns={'ged_sb_best_count_nokgi':'candidate_sb_count'}, inplace=True)\n",
    "\n",
    "# rename 'ged_ns_best_count_nokgi' to 'candidate_ns_count'\n",
    "combined_df.rename(columns={'ged_ns_best_count_nokgi':'candidate_ns_count'}, inplace=True)\n",
    "\n",
    "# rename 'ged_os_best_count_nokgi' to 'candidate_os_count'\n",
    "combined_df.rename(columns={'ged_os_best_count_nokgi':'candidate_os_count'}, inplace=True)\n",
    "\n",
    "# rename 'ged_sb_high_count_nokgi' to 'candidate_sb_high_count'\n",
    "combined_df.rename(columns={'ged_sb_high_count_nokgi':'candidate_sb_high_count'}, inplace=True)\n",
    "\n",
    "# rename 'ged_ns_high_count_nokgi' to 'candidate_ns_high_count'\n",
    "combined_df.rename(columns={'ged_ns_high_count_nokgi':'candidate_ns_high_count'}, inplace=True)\n",
    "\n",
    "# rename 'ged_os_high_count_nokgi' to 'candidate_os_high_count'\n",
    "combined_df.rename(columns={'ged_os_high_count_nokgi':'candidate_os_high_count'}, inplace=True)\n",
    "\n",
    "combined_df.drop(columns=['source_version'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'c_id':'int'})\n",
    "df = df.astype({'cm_id':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.cm.db_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the uniqueness of country_id and month combinations\n",
    "print('Is this CM unique?', df.cm.is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingestion Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingestion function, adjust as needed to either keep the outpanel or wipe it\n",
    "def ingestion(data, table_name):\n",
    "    \"\"\"ingestion step.\"\"\"\n",
    "    print(f\"ingestion step\")\n",
    "    cm_writer = DBWriter(data, \"cm\",\n",
    "                   in_panel_wipe = True,\n",
    "                   out_panel_wipe = False,\n",
    "                   in_panel_zero = True,\n",
    "                   out_panel_zero = False)  \n",
    "    cm_writer.set_time_extents_min_max(data.month_id.min(), data.month_id.max())\n",
    "    cm_writer.transfer(tname=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestion(df, 'nowcasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ingestion step\n",
    "#ingestion(data, 'nowcasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!viewser features list cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
